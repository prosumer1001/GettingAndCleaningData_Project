---
title: "Coursera: *Getting and Cleaning Data* - README"
author:  Nick T.
output: html_notebook
---

```{r, load_libraries, echo = FALSE, warning = FALSE, message = FALSE}
  ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
      install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
  }
  # Install and Load Packages
  packages <- c("purrr",
                "rio", 
                "tidyverse",
                "stringr")
  ipak(packages)
```

# Code Table of Contents (TOC)

### 1. SECION 1 - Import Data
|      A. y_test (TEST LABELS)
|      B. y_train (TRAINING LABELS)
|      C. x_test (TEST DATA)
|      D. x_train (TRAINING DATA)
|      E. subject_test (TEST SUBJECTS)
|      F. subject_train (TRAINING SUBJECTS)
|      G. activity_lables (ACTIVITY FACTOR LABELS)
|      H. features (VARIABLE NAMES AS A FEATURES VECTOR)

### 2. SECTION 2 - Create the datasets data frames
|      A. Create the rows data frame
|      B. Create the xtestResults and xtrainResults data frames. 

### 3. SECTION 3 - Add front matter to xtrainResults and xtestResults DFs.
|      A. Build the xtest results DF with front matter
|      B. Build the xtrain results DF with front matter

### 4. SECTION 4 - Add experimentType column to each DF, "train" for training and
|      A. Add column for experimentType for testing.
|      B. Add column for experimentType for training

### 5. SECTION 5 - Merge xtrainResults and xtestResults into `completeDF`, a single tidy data frame.
|      A. Rename subjectID variables to be identical for both data frames
|      B. dplyr bind_rows()

# Preface 

The Coursera course *Getting and Cleaning Data* CODEBOOK is intended to provide the user with enough information to replicate the data analysis in the project.  Users of the CODEBOOK should be able to understand how the data was tidyed to its current state.  

The `CODEBOOK` is a companion to the `run_analysis.R` and `README.md` files.  The github repository is located at https://github.com/prosumer1001/GettingAndCleaningData_Project.  Direct all questions to the author at prosumer1001@gmail.com.

# Instructions

### Review Criteria

1. The submitted data set is tidy.
2. The Github repo contains the required scripts.
3. GitHub contains a code book that modifies and updates the available codebooks with the data to indicate all the variables and summaries calculated, along with units, and any other relevant information.
4. The README that explains the analysis files is clear and understandable.
5. The work submitted for this project is the work of the student who submitted it.

### Course Project Description 

The course project description is copied verbatim from the site.[^1]

The purpose of this project is to demonstrate your ability to collect, work with, and clean a data set. The goal is to prepare tidy data that can be used for later analysis. You will be graded by your peers on a series of yes/no questions related to the project. You will be required to submit: 1) a tidy data set as described below, 2) a link to a Github repository with your script for performing the analysis, and 3) a code book that describes the variables, the data, and any transformations or work that you performed to clean up the data called `CodeBook.md`. You should also include a `README.md` in the repo with your scripts. This `README.md` explains how all of the scripts work and how they are connected.

One of the most exciting areas in all of data science right now is wearable computing - see for example <a href="http://www.insideactivitytracking.com/data-science-activity-tracking-and-the-battle-for-the-worlds-top-sports-brand/" target="_blank" rel="noopener nofollow">this article </a>. Companies like Fitbit, Nike, and Jawbone Up are racing to develop the most advanced algorithms to attract new users. The data linked to from the course website represent data collected from the accelerometers from the Samsung Galaxy S smartphone. A full description is available at the site where the data was obtained:

http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones

Here are the data for the project:

https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip

You should create one R script called run_analysis.R that does the following.

1. Merges the training and the test sets to create one data set.
2. Extracts only the measurements on the mean and standard deviation for each measurement.
3. Uses descriptive activity names to name the activities in the data set
4. Appropriately labels the data set with descriptive variable names.
5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.

# README

The data codebook can be obtained from the author's .git repository, `GettingAndCleaningData_Project` titled `HARreadme.txt`.  The final tidy dataframe `CODEBOOK.Rmd` that accompany's this project provides detailes for each variable according to the original coding rubric.

# Step 1. Import data.  

```{r, SECTION01, echo = TRUE, message = FALSE, warning = FALSE}
if(T){ ## BEGIN SECTION 1 - IMPORT DATA ##
## 1. Import Data
        ## 0. Paths
testpath <- "~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/test"
trainingpath <- "~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/training"
testinertials<- "~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/test/InertialSignals"
traininginertials<- "~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/training/InertialSignals"
processeddata <- "~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/processed"
        ## A. y_test (TEST LABLES)
y_test <- import("~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/test/y_test.txt") ## load the y_test.txt data file
y_test <- tibble::rowid_to_column(y_test, "ID") ## create a unique variable named `ID` in the y_test for left_join(by = "ID")
y_test <- y_test %>% rename(factor = "V1"); str(y_test)

        ## B. y_train (TRAINING LABELS)
y_train <- import("~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/train/y_train.txt")
y_train <- tibble::rowid_to_column(y_train, "ID") ## create a unique variable named `ID` in the y_train for left_join(by = "ID")
str(y_train)
y_train <- y_train %>% rename(factor = "V1"); str(y_train)

        ## C. x_test (TEST DATA)
x_test <- import("~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/test/x_test.txt") # import features.txt data into working environment
x_test <- tibble::rowid_to_column(x_test, "ID"); names(x_test)
# ID <- x_test %>% select(ID); names(ID)
names(x_test)
# x_test <- x_test %>% select(-ID); names(x_test)
# x_test <- cbind(x_test, ID); names(x_test)

        ## D. x_train (TRAINING DATA)
x_train <- import("~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/train/x_train.txt") # import features.txt data into working environment
x_train <- tibble::rowid_to_column(x_train, "ID"); names(x_train)
# ID <- x_train %>% select(ID); names(ID)
names(x_train)
# x_train <- x_train %>% select(-ID); names(x_train)
# x_train <- cbind(x_train, ID); names(x_train)

        ## E. subject_test (TEST)
subject_test <- import("~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/test/subject_test.txt") ## load the subject_test.txt (the person's ID number that was in the test) data file
subject_test <- tibble::rowid_to_column(subject_test, "ID"); str(subject_test) ## create a unique variable named `ID` in the subject_test for left_join(by = "ID")
subject_test <- subject_test %>% rename(subjecttestID = "V1"); str(subject_test)

        ## F. subject_train
subject_train <- import("~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/train/subject_train.txt") ## load the subject_train.txt data file)
subject_train <- tibble::rowid_to_column(subject_train, "ID"); str(subject_train) ## create a unique variable named `ID` in the subject_train for left_join(by = "ID")
subject_train <- subject_train %>% rename(subjecttrainID = "V1"); str(subject_train)

        ## G. activity_lables
activity_labels <- import("~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/activity_labels.txt") ## load the activity_labels.txt data file
labelsDF <- import("~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/activity_labels.txt") # import labelsDF.RData
labelsDF <- labelsDF %>% rename(ID = "V1")
labelsDF <- labelsDF %>% rename(label = "V2"); str(labelsDF)
labelsDF <- labelsDF %>% mutate(factor = ID); str(labelsDF)
labelsDF <- labelsDF %>% select(ID, factor, label)
export(labelsDF, file = "~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Processed/labels.RData")
labelsDF <- import("~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Processed/labels.RData")

        ## H. features
features <- import("~/Documents/gitrepos/DataAnalysis/GettingAndCleaningData_Project/Project/Data/Raw/features.txt"); head(features) # import features.txt data into working environment
ID <- "ID"
features <- rbind(features, ID); names(features); head(features); tail(features); sample_n(features, 10)

} ## END SECTION 1 ##
```



# Step 2. Process data frames into untidy data frame and add frontmatter to the x_test and x_train data.

```{r, SECTION02, echo = TRUE, message = FALSE, warning = FALSE}
if(T){ ## BEGIN SECTION 2 ##
##      A. Create the rows data frame that will select the correct variables
##         from the x_test and x_train data frames in Section 3.  This step
##         was necessary because when using regex and grep there were duplicate
##         names in the features.txt data frame.  Thus, removing all except
##         the columns specified in the instructions became a necessary
##         pre-condition to successfully creating the test and training
##         data frames.

rows01 <- features %>% filter(grepl("mean",V2)); str(rows01) # create a new df of only the `mean` values (instructions, requirement #2)
# rows01$V1 <- as.numeric(rows01$V1); str(rows01) # make V1 numeric value
rows01 <- rows01 %>% arrange(V1); rows01; str(rows01) # arrange from smallest to largest
rows02 <- features %>% filter(grepl("std", V2)); rows02; str(rows02) # create a new df of only the `sd` values (instructions, requirement #2)
# rows02$V1 <- as.numeric(rows02$V1); str(rows02) # make V1 numeric value
rows02 <- rows02 %>% arrange(V1); str(rows02) # arrange from smallest to largest
rows01 <- rows01 %>% rename(ID = "V1"); rows01; str(rows01) # rename the V1 to ID
rows02 <- rows02 %>% rename(ID = "V1"); rows02; str(rows02) # rename the V1 to ID
rows <- full_join(rows01, rows02, by = "ID"); names(rows); sample_n(rows, 25) # join rows01 & rows02
rows <- as_tibble(rows) # make rows a tibble
rows <- unite(rows, FEATURE, V2.x:V2.y, na.rm = TRUE, remove = TRUE) # unite the columns into a single column
rows <- rows %>% arrange(ID); rows # arrange from smallest to largest
rows <- rows %>% mutate(ID2 = ID); names(rows); rows
rows <- rows %>% select(ID, ID2, FEATURE)
rows$ID <- as.character(rows$ID) # convert each observation to character
str(rows)
rows$ID <- paste("V", rows$ID) # add a `V` to each observation
rows$ID <- gsub(" ", "", rows$ID) # remove all the white spaces
rows$FEATURE <- str_replace_all(rows$FEATURE, "[[:punct:]]", "") # remove all special characters

##      B. Create the xtestResults and xtrainResults data frames with ID column
xtestResults <- select(x_test, .dots = rows$ID); # create df that only includes the mean and std variables for the test results 
names(xtestResults) <- rows$FEATURE; # Make the vector FEATURE the column names for xtestResults
xtestResults <- tibble::rowid_to_column(xtestResults, "ID"); names(xtestResults)

xtrainResults <- select(x_train, .dots = rows$ID); # create df that only includes the mean and std variables for the train results 
names(xtrainResults) <- rows$FEATURE; # Make the vector FEATURE the column names for xtrainResults
xtrainResults <- tibble::rowid_to_column(xtrainResults, "ID"); names(xtrainResults)

} ## END SECTION 2 ##

```

## Variable name rules / coding rules.  

The `raw` datasets exist in eight text files:

* x_train
* y_train
* subject_train
* x_test
* y_test
* subject_test
* features
* activity_labels

The x_train and x_test files containe all of the observational data.  The y_train and y_test files contain the subject number by observation row.  The features text file provides variable names for the 561 unique variables for the experimentation in training and testing.  The activity labels text file provides the factor levels for the different observations.  For example, observation 558 is a walking variable, which needs to be accurately matches with the x_train and x_test observations.

> The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. 

> Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). 

> Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the 'f' to indicate frequency domain signals). 

> These signals were used to estimate variables of the feature vector for each pattern:  
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.

The difference between the original file and the naming conventions used in this data frame include the removal of all special characters (i.e. **-** and **()**).  Additionally, all characters were changed to lower case.  Thus, a prior exmaple might be:  `fBodyAccJerkMag` and the new variable name is `fbodyaccjerkmag`.  While the lack of upper case letters may make deciphering the variable more difficult at first, it will make errors in the code of future uesers less likely to occur.  The practical benefits is that a major transformation has not taken place, so using the original code-book ensures replicability with less errors, which should increase the likelyhood of replication, all else equal.

# Step 3. Process the y_test.txt dataset, the activity_labels.txt dataset, and the subject_test.txt data sets.  

```{r, SECTION03, echo = TRUE, message = FALSE, warning=FALSE}
if(T){## BEGIN SECTION 3 ##
##      3. Add front matter to xtrainResults and xtestResults DFs.  Code below creates two data frames: xtestResults & xtrainResults WITH front matter.
##        A. Build the xtest results DF with front matter
frontMatterTest <- left_join(y_test, subject_test, by = "ID"); str(frontMatterTest); names(frontMatterTest)
frontMatterTest <- left_join(frontMatterTest, labelsDF, by = "factor"); str(xtestResults);  names(frontMatterTest)
frontMatterTest <- frontMatterTest %>% rename(ID = ID.x)
frontMatterTest <- frontMatterTest %>% select(-ID.y)
xtestResults <- left_join(frontMatterTest, xtestResults, by = "ID"); str(xtestResults) ## left join by the ID variable

##        B. Build the xtrain results DF with front matter
frontMatterTrain <- left_join(y_train, subject_train, by = "ID"); str(frontMatterTrain); names(frontMatterTrain)
frontMatterTrain <- left_join(frontMatterTrain, labelsDF, by = "factor"); str(xtrainResults);  names(frontMatterTrain)
frontMatterTrain <- frontMatterTrain %>% rename(ID = ID.x)
frontMatterTrain <- frontMatterTrain %>% select(-ID.y)
xtrainResults <- left_join(frontMatterTrain, xtrainResults, by = "ID"); str(xtrainResults) ## left join by the ID variable

# View(xtrainResults)
# View(xtestResults)


} ## END SECTION 3 ##

```


There will be many variables since both the training and the test data have the same variables--each of which has 561 variables. The approach used is to create a tidy test variable and training variable.  After the training data frame is made tidy it can be bound to the tidy test data frame by rows.

# Step 4. Create an experiementType column so the final dataset remains in tidy form.

```{r, SECTION04, echo = TRUE, message=FALSE, warning=FALSE}
if(T){ ## BEGIN SECTION 4 ##
##      4. Add experimentType column to each DF, "train" for training and
##              "test" for testing
##        A. Add column for experimentType for testing.
experimentType <- data.frame(experimentType = "test", stringsAsFactors = FALSE)
experimentType <- experimentType %>% slice(rep(1:n(), each=2947)); str(experimentType)
experimentType <- tibble::rowid_to_column(experimentType, "ID"); str(experimentType)
xtestResults <- left_join(xtestResults, experimentType); names(xtestResults)
xtestResults <- xtestResults %>% select(ID, factor, subjecttestID, label, experimentType, everything()); names(xtestResults)

##        B. Add column for experimentType for training
experimentType <- data.frame(experimentType = "train", stringsAsFactors = FALSE)
experimentType <- experimentType %>% slice(rep(1:n(), each=7352)); str(experimentType)
experimentType <- tibble::rowid_to_column(experimentType, "ID"); str(experimentType)
xtrainResults <- left_join(xtrainResults, experimentType); names(xtrainResults)
xtrainResults <- xtrainResults %>% select(ID, factor, subjecttrainID, label, experimentType, everything()); names(xtrainResults)

        } ## END SECTION 4 ##
```


# Step 5. Merge the datasets into the final, `completeDF` dataset.  The dataset is tidy and has the appropriate frontmatter for statistical analysis.

```{r, SECTION05, echo = TRUE, message = FALSE, warning = FALSE}
if(T){ ## BEGIN SECION 5 ##
##      5. Merge xtrainResults and xtestResults into `completeDF`, a single 
##              tidy dataset.

##        A. Rename subjectID variables to be identical for both data frames
##              and verify.
xtestResults <- xtestResults %>% rename(subjectID = "subjecttestID") # rename subjecttestID
xtrainResults <- xtrainResults %>% rename(subjectID = "subjecttrainID") # rename subjectrainID
all_equal(xtestResults, xtrainResults, ignore_col_order = FALSE, ignore_row_order = TRUE) # verify the columns are identical
##      output:  > [1] "Different number of rows" >> Indicates the columns are identical

##        B. dplyr bind_rows()

completeDF <- bind_rows(xtestResults, xtrainResults)
str(completeDF)

} ## END SECTION 5 ##
```

# Conclusion

The data frame, `completeDF` fulfills the requirements outlines in review criteria.  All code is commented in the scripting and the README.Rmd file provides further explanation.

1. The submitted data set is tidy.
2. The Github repo contains the required scripts.
3. GitHub contains a code book that modifies and updates the available codebooks with the data to indicate all the variables and summaries calculated, along with units, and any other relevant information.
4. The README that explains the analysis files is clear and understandable.
5. The work submitted for this project is the work of the student who submitted it.

[^1]: from https://www.coursera.org/learn/data-cleaning/peer/FIZtT/getting-and-cleaning-data-course-project
